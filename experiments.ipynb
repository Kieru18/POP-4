{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 19:35:43.271810: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 19:35:43.311583: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 19:35:43.312500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-29 19:35:44.343978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "from CONST import SEED, POPULATION_SIZE, GENERATIONS, HISTORY_PATH\n",
    "from neural_networks import FNN, CNN, CRNN\n",
    "from utils import (set_seed, plot_confusion_matrix, make_predictions, \n",
    "                   calculate_metrics, save_metrics, save_history)\n",
    "from algorithms import mu_lambda_es_evolve, de_best_1_bin_evolve, load_population, save_population\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv2D, MaxPooling2D, Reshape\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(HISTORY_PATH):\n",
    "    os.makedirs(HISTORY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(test_images, test_labels, test_size=2000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 19:35:47.472833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-29 19:35:47.473382: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 1.8042 - accuracy: 0.5021\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1056 - accuracy: 0.7804\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.8336\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.8560\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.8711\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'history/FNN_SGD.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 45\u001b[0m\n\u001b[1;32m     33\u001b[0m     best_individual2, pop, history \u001b[38;5;241m=\u001b[39m mu_lambda_es_evolve(mu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m     34\u001b[0m                                                          lambda_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m     35\u001b[0m                                                          sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m                                                          variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     41\u001b[0m                                                          start_pop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_weights(best_individual)\n\u001b[0;32m---> 45\u001b[0m \u001b[43msave_history\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m make_predictions(model, test_images)\n\u001b[1;32m     49\u001b[0m accuracy, precision, recall, conf_matrix \u001b[38;5;241m=\u001b[39m calculate_metrics(predicted_labels, np\u001b[38;5;241m.\u001b[39margmax(test_labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/mnt/d/studia/sem5/POP/projekt/POP-4/utils.py:77\u001b[0m, in \u001b[0;36msave_history\u001b[0;34m(model_name, history)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_history\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, history: List[\u001b[38;5;28mfloat\u001b[39m]):\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mHISTORY_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     78\u001b[0m             json\u001b[38;5;241m.\u001b[39mdump(history, f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'history/FNN_SGD.json'"
     ]
    }
   ],
   "source": [
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "models: List[Model] = [\n",
    "    FNN('SGD'), FNN('ES'), FNN('DE'),\n",
    "    CNN('SGD'), CNN('ES'), CNN('DE'),\n",
    "    # CRNN('SGD'), CRNN('ES'), CRNN('DE')\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    if model.info == 'SGD':\n",
    "        model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history_obj = model.fit(train_images, train_labels, epochs=5, batch_size=64, shuffle=True)\n",
    "        history = history_obj.history['accuracy']\n",
    "\n",
    "    elif model.info == 'ES':\n",
    "        model.build((1, 28, 28))\n",
    "\n",
    "        best_individual, pop, history = de_best_1_bin_evolve(population_size=POPULATION_SIZE, \n",
    "                                                             generations=GENERATIONS, \n",
    "                                                             model=model, \n",
    "                                                             F=1, \n",
    "                                                             CR=0.2, \n",
    "                                                             test_images=val_images,\n",
    "                                                             test_labels=val_labels, \n",
    "                                                             variant='cross', \n",
    "                                                             start_pop=None)\n",
    "        \n",
    "        model.set_weights(best_individual)\n",
    "\n",
    "    elif model.info == 'DE':\n",
    "        model.build((1, 28, 28))\n",
    "\n",
    "        best_individual2, pop, history = mu_lambda_es_evolve(mu=5, \n",
    "                                                             lambda_=5, \n",
    "                                                             sigma=0.1, \n",
    "                                                             generations=10, \n",
    "                                                             test_images=val_images,\n",
    "                                                             test_labels=val_labels, \n",
    "                                                             model=model,  \n",
    "                                                             variant='cross', \n",
    "                                                             start_pop=None)\n",
    "\n",
    "        model.set_weights(best_individual)\n",
    "\n",
    "    save_history(str(model), history)\n",
    "\n",
    "    predicted_labels = make_predictions(model, test_images)\n",
    "\n",
    "    accuracy, precision, recall, conf_matrix = calculate_metrics(predicted_labels, np.argmax(test_labels, axis=1))\n",
    "    save_metrics(str(model), accuracy=accuracy, precision=precision, recall=recall)\n",
    "    # print(f'{str(model)} Evaluation - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "    # print('Confusion Matrix:')\n",
    "    # print(conf_matrix)\n",
    "    \n",
    "    plot_confusion_matrix(conf_matrix, class_names, title=f'{str(model)}', save=True)\n",
    "\n",
    "    model.save(f'models/{str(model)}', save_format='tf')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
