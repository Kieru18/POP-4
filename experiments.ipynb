{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 20:24:58.834419: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 20:24:58.911450: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 20:24:58.912682: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-29 20:25:00.776043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "from CONST import SEED, POPULATION_SIZE, GENERATIONS, HISTORY_PATH\n",
    "from neural_networks import FNN, CNN, CRNN\n",
    "from utils import (set_seed, plot_confusion_matrix, make_predictions, \n",
    "                   calculate_metrics, save_metrics, save_history)\n",
    "from algorithms import mu_lambda_es_evolve, de_best_1_bin_evolve, load_population, save_population\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv2D, MaxPooling2D, Reshape\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(HISTORY_PATH):\n",
    "    os.makedirs(HISTORY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(test_images, test_labels, test_size=2000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 20:25:03.802747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-29 20:25:03.803277: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 1.8042 - accuracy: 0.5021\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.1056 - accuracy: 0.7804\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.8336\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.8560\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.8711\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "INFO:tensorflow:Assets written to: models/FNN_SGD/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/FNN_SGD/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 27607.00390625\n",
      "\n",
      "--------------------------\n",
      "Evolution - generation: 0\n",
      "Individual number: 0_0\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 28989.21875\n",
      "Individual number: 0_1\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 28819.06640625\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Acc: -0.134\n",
      "\n",
      "--------------------------\n",
      "Evolution - generation: 1\n",
      "Individual number: 1_0\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 29081.24609375\n",
      "Individual number: 1_1\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 28978.22265625\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Acc: -0.134\n",
      "\n",
      "--------------------------\n",
      "Evolution - generation: 2\n",
      "Individual number: 2_0\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 27680.93359375\n",
      "Individual number: 2_1\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 28030.234375\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Acc: -0.134\n",
      "\n",
      "--------------------------\n",
      "Evolution - generation: 3\n",
      "Individual number: 3_0\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26888.171875\n",
      "Individual number: 3_1\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 28175.234375\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Acc: -0.134\n",
      "\n",
      "--------------------------\n",
      "Evolution - generation: 4\n",
      "Individual number: 4_0\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26972.6640625\n",
      "Individual number: 4_1\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "Fitness of working point: (26459.422,)\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 28892.0625\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "___________________\n",
      "Acc: -0.134\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 26459.421875\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "___________________\n",
      "Cross-entropy Loss: 27607.00390625\n",
      "(26459.421875,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m stop \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     49\u001b[0m runtime \u001b[38;5;241m=\u001b[39m stop \u001b[38;5;241m-\u001b[39m start\n\u001b[0;32m---> 51\u001b[0m \u001b[43msave_history\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m;\n\u001b[1;32m     53\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m make_predictions(model, test_images)\n\u001b[1;32m     55\u001b[0m accuracy, precision, recall, conf_matrix \u001b[38;5;241m=\u001b[39m calculate_metrics(predicted_labels, np\u001b[38;5;241m.\u001b[39margmax(test_labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/mnt/d/studia/sem5/POP/projekt/POP-4/utils.py:79\u001b[0m, in \u001b[0;36msave_history\u001b[0;34m(model_name, history, plot)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_history\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, history: List[\u001b[38;5;28mfloat\u001b[39m], plot: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHISTORY_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 79\u001b[0m         \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plot:\n\u001b[1;32m     82\u001b[0m         label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerations\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mES\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDE\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m \n",
      "File \u001b[0;32m/usr/lib/python3.8/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1100x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "models: List[Model] = [\n",
    "    FNN('SGD'), FNN('ES'), FNN('DE'),\n",
    "    CNN('SGD'), CNN('ES'), CNN('DE'),\n",
    "    # CRNN('SGD'), CRNN('ES'), CRNN('DE')\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    start = time.time()\n",
    "    if model.info == 'SGD':\n",
    "        model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history_obj = model.fit(train_images, train_labels, epochs=5, batch_size=64, shuffle=True)\n",
    "        history = history_obj.history['accuracy']\n",
    "\n",
    "    elif model.info == 'ES':\n",
    "        model.build((1, 28, 28, 1))\n",
    "\n",
    "        best_individual, pop, history = de_best_1_bin_evolve(population_size=POPULATION_SIZE, \n",
    "                                                             generations=GENERATIONS, \n",
    "                                                             model=model, \n",
    "                                                             F=1, \n",
    "                                                             CR=0.2, \n",
    "                                                             test_images=val_images,\n",
    "                                                             test_labels=val_labels, \n",
    "                                                             variant='cross', \n",
    "                                                             start_pop=None)\n",
    "        \n",
    "        model.set_weights(best_individual)\n",
    "        history = np.multiply(history, -1).tolist()\n",
    "\n",
    "    elif model.info == 'DE':\n",
    "        model.build((1, 28, 28, 1))\n",
    "\n",
    "        best_individual2, pop, history = mu_lambda_es_evolve(mu=5, \n",
    "                                                             lambda_=5, \n",
    "                                                             sigma=0.1, \n",
    "                                                             generations=10, \n",
    "                                                             test_images=val_images,\n",
    "                                                             test_labels=val_labels, \n",
    "                                                             model=model,  \n",
    "                                                             variant='cross', \n",
    "                                                             start_pop=None)\n",
    "\n",
    "        model.set_weights(best_individual)\n",
    "        history = np.multiply(history, -1).tolist()\n",
    "\n",
    "    stop = time.time()\n",
    "    runtime = stop - start\n",
    "\n",
    "    save_history(str(model), history, plot=True);\n",
    "\n",
    "    predicted_labels = make_predictions(model, test_images)\n",
    "\n",
    "    accuracy, precision, recall, conf_matrix = calculate_metrics(predicted_labels, np.argmax(test_labels, axis=1))\n",
    "    save_metrics(str(model), accuracy=accuracy, precision=precision, recall=recall, time=runtime)\n",
    "    # print(f'{str(model)} Evaluation - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "    # print('Confusion Matrix:')\n",
    "    # print(conf_matrix)\n",
    "    \n",
    "    plot_confusion_matrix(conf_matrix, class_names, title=f'{str(model)}', save=True)\n",
    "\n",
    "    model.save(f'models/{str(model)}', save_format='tf')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
